{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_shape, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.image_size = 3 * 64 * 64\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, z_dim)\n",
    "        self.fc2 = nn.Linear(256 * 2 * 2, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, 256 * 2 * 2)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(256 * 2 * 2, 128, 5, stride=2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, stride=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 6, stride=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 6, stride=2)\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.conv4(h))\n",
    "        h = h.view(-1, 256 * 2 * 2)\n",
    "        return self.fc1(h), self.fc2(h)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Generate latent vector from mean and stddev\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.fc3(z).view(-1, 256 * 2 * 2, 1, 1)\n",
    "        h = F.relu(self.deconv1(h))\n",
    "        h = F.relu(self.deconv2(h))\n",
    "        h = F.relu(self.deconv3(h))\n",
    "        h = F.sigmoid(self.deconv4(h))\n",
    "        return h\n",
    "\n",
    "\n",
    "    def forward(self, x, encode=False, mean=False):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        if encode:\n",
    "            if mean:\n",
    "                return mu\n",
    "            return z\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size=20):\n",
    "        \"\"\" Instanciate a dataset extending PyTorch \"\"\"\n",
    "        self.frames = []\n",
    "        for i in os.listdir('/floyd/input/car_racing_data/'):\n",
    "            obs = np.load(os.path.join('/floyd/input/car_racing_data', i))['obs']\n",
    "            for ob in obs:\n",
    "                self.frames.append(ToTensor()(Image.fromarray(ob).resize((64,64))))\n",
    "#         for i in os.listdir('/floyd/input/driving_data/'):\n",
    "#             obs = ToTensor()(np.array(Image.open(os.path.join('/floyd/input/driving_data/', i)).resize((64,64))))\n",
    "#             self.frames.append(obs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.frames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    batch_size = x.size()[0]\n",
    "    loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "#     loss /= batch_size\n",
    "#     kld /= batch_size\n",
    "    return loss + kld\n",
    "\n",
    "record_loss = []\n",
    "def train_vae():\n",
    "    \"\"\"Train a VAE to create a latent representation environment\"\"\"\n",
    "    epochs = 5\n",
    "    vae = VAE((320, 160, 3), 50).to(device)\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    \n",
    "    dataset = VAEDataset()\n",
    "    training_set = DataLoader(dataset, batch_size=128, num_workers=4, shuffle=True)\n",
    "    for e in range(epochs):\n",
    "        print(\"Epoch: {}/{}\".format(e+1, epochs))\n",
    "        for i, frames in enumerate(training_set):\n",
    "            optimizer.zero_grad()\n",
    "            #print frames\n",
    "            frames = frames.to(device)\n",
    "            recon_x, mu, logvar = vae(frames)\n",
    "            loss = loss_fn(recon_x, frames, mu, logvar)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            record_loss.append(loss)\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(\"Loss: {}\".format(float(loss.data)))\n",
    "        \n",
    "    torch.save(vae.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7a907f6ad832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a8fdee759dca>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAEDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-491224f646c8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/floyd/input/car_racing_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#         for i in os.listdir('/floyd/input/driving_data/'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#             obs = ToTensor()(np.array(Image.open(os.path.join('/floyd/input/driving_data/', i)).resize((64,64))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m     def rotate(self, angle, resample=NEAREST, expand=0, center=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE((320, 160, 3), 50)\n",
    "vae.load_state_dict(torch.load('model.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test VAE\n",
    "img = np.load('/floyd/input/car_racing_data/trial_1995_0.npz')['obs'][120]\n",
    "img = Image.fromarray(img).resize((64,64))\n",
    "plt.imshow(img)\n",
    "im = vae(ToTensor()(img).unsqueeze_(0),encode=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = im.permute((0,2,3,1))\n",
    "im_to_show = img.detach().numpy()[0]\n",
    "plt.imshow(im_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_UNTIS = 256\n",
    "z_dim = 50\n",
    "\n",
    "class VRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VRNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, z_dim)\n",
    "\n",
    "        self.encoder = nn.Linear(50+256,50*2) # output hyperparameters\n",
    "        self.phi_z = nn.Sequential(nn.Linear(50,50), nn.ReLU())\n",
    "        \n",
    "        self.fc3 = nn.Linear(z_dim+256, 256 * 2 * 2)\n",
    "        self.deconv1 = nn.ConvTranspose2d(256 * 2 * 2, 128, 5, stride=2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, stride=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 6, stride=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 6, stride=2)\n",
    "\n",
    "        self.prior = nn.Linear(256,50*2) # output hyperparameters\n",
    "        self.rnn = nn.GRUCell(50*2,256)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # Feature extraction\n",
    "        #x = x.unsqueeze_(0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        z_prior = self.prior(hidden)\n",
    "        z_infer = self.encoder(torch.cat([x,hidden], dim=1))\n",
    "        z = Variable(torch.randn(x.size(0),50)).to(device)*z_infer[:,50:].exp()+z_infer[:,:50]\n",
    "        z = self.phi_z(z)\n",
    "        \n",
    "        # Decode\n",
    "        x_out = self.fc3(torch.cat([x,hidden], dim=1)).view(-1, 256 * 2 * 2, 1, 1)\n",
    "        x_out = F.relu(self.deconv1(x_out))\n",
    "        x_out = F.relu(self.deconv2(x_out))\n",
    "        x_out = F.relu(self.deconv3(x_out))\n",
    "        x_out = F.sigmoid(self.deconv4(x_out))\n",
    "        \n",
    "        hidden_next = self.rnn(torch.cat([x,z], dim=1),hidden)\n",
    "        return x_out, hidden_next, z_prior, z_infer\n",
    "    \n",
    "    def calculate_loss(self, x, hidden):\n",
    "        x_out, hidden_next, z_prior, z_infer = self.forward(x, hidden)\n",
    "        loss1 = nn.functional.binary_cross_entropy(x_out, x, reduction='sum')\n",
    "        \n",
    "        mu_infer, log_sigma_infer = z_infer[:,:50], z_infer[:,50:]\n",
    "        mu_prior, log_sigma_prior = z_prior[:,:50], z_prior[:,50:]\n",
    "        loss2 = (2*(log_sigma_infer-log_sigma_prior)).exp() \\\n",
    "                + ((mu_infer-mu_prior)/log_sigma_prior.exp())**2 \\\n",
    "                - 2*(log_sigma_infer-log_sigma_prior) - 1\n",
    "        loss2 = 0.5*loss2.sum(dim=1).mean()\n",
    "        return loss1, loss2, hidden_next\n",
    "    \n",
    "    def generate(self, hidden=None, temperature=None):\n",
    "        if hidden is None:\n",
    "            hidden = Variable(torch.zeros(1,256)).to(device)\n",
    "        if temperature is None:\n",
    "            temperature = 0.8\n",
    "        z_prior = self.prior(hidden)\n",
    "        z = Variable(torch.randn(z_prior.size(0),50)).to(device)*z_prior[:,50:].exp()+z_prior[:,:50]\n",
    "        z = self.phi_z(z)\n",
    "        \n",
    "        x_out = self.fc3(torch.cat([hidden, z], dim=1)).view(-1, 256*2*2,1,1)\n",
    "        x_out = F.relu(self.deconv1(x_out))\n",
    "        x_out = F.relu(self.deconv2(x_out))\n",
    "        x_out = F.relu(self.deconv3(x_out))\n",
    "        x_out = F.sigmoid(self.deconv4(x_out))\n",
    "        x_sample = x = x_out.div(temperature)\n",
    "        x_sample = x_sample.exp().squeeze_(0)\n",
    "        gen_image = []\n",
    "        for chan in x_sample:\n",
    "            gen_image.append(chan.multinomial(64).tolist())\n",
    "        gen_image_ar = torch.Tensor(gen_image) / 255.0\n",
    "        print(gen_image_ar.shape)\n",
    "        x = gen_image_ar\n",
    "        x = x.unsqueeze_(0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = self.fc1(x)\n",
    "        hidden_next = self.rnn(torch.cat([x,z], dim=1), hidden)\n",
    "        return gen_image_ar[0], hidden_next\n",
    "    \n",
    "    def generate_images(self, n=10, temperature=None, hidden=None):\n",
    "        for _ in range(n):\n",
    "            x_sample, hidden = self.generate(hidden, temperature)\n",
    "            print(x_sample.shape)\n",
    "            x_sample = x_sample.permute((1,2,0))\n",
    "            plt.imshow(x_sample)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vrnn():\n",
    "    vrnn = VRNN().to(device)\n",
    "    hidden = Variable(torch.zeros(200,256)).to(device)\n",
    "    optimizer = torch.optim.Adam(vrnn.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    dataset = LSTMDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=1, num_workers=1, collate_fn=collate_fn)\n",
    "    epochs = 2\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        print(\"Epoch: {}/{}\".format(e+1, epochs))\n",
    "        for batch_idx, (frames, actions) in enumerate(dataloader):\n",
    "            frames = frames.squeeze_(0).to(device)\n",
    "            #actions = actions.squeeze_(0).to(device)\n",
    "            x = frames\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss1, loss2, hidden = vrnn.calculate_loss(x, hidden)\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            hidden.detach_()\n",
    "            if batch_idx % 20 == 0:\n",
    "                print('loss: {}'.format(loss))\n",
    "                print('bce loss: {}'.format(loss1))\n",
    "                print('kl loss: {}'.format(loss2))\n",
    "    \n",
    "    torch.save(vrnn.state_dict(), 'vrnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1701696.5\n",
      "bce loss: 1701696.375\n",
      "kl loss: 0.18613851070404053\n",
      "loss: 1555033.25\n",
      "bce loss: 1555032.625\n",
      "kl loss: 0.6294601559638977\n",
      "loss: 1454594.125\n",
      "bce loss: 1454594.0\n",
      "kl loss: 0.17732812464237213\n",
      "loss: 1399301.75\n",
      "bce loss: 1399301.625\n",
      "kl loss: 0.1107688620686531\n",
      "loss: 1381183.125\n",
      "bce loss: 1381183.0\n",
      "kl loss: 0.06721028685569763\n",
      "Epoch: 2/2\n",
      "loss: 1337625.5\n",
      "bce loss: 1337625.5\n",
      "kl loss: 0.0610223226249218\n",
      "loss: 1385643.875\n",
      "bce loss: 1385643.75\n",
      "kl loss: 0.13657361268997192\n",
      "loss: 1403288.75\n",
      "bce loss: 1403288.75\n",
      "kl loss: 0.05012085288763046\n",
      "loss: 1382155.0\n",
      "bce loss: 1382155.0\n",
      "kl loss: 0.03593295440077782\n",
      "loss: 1362082.25\n",
      "bce loss: 1362082.25\n",
      "kl loss: 0.03605717048048973\n"
     ]
    }
   ],
   "source": [
    "train_vrnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEYBJREFUeJzt3XuMXOV5x/Hvj2WpU6AxF9dybKsQsIL8RzGJRUCgikCJyEUBRQiFRpWFXC1KoSJqKmLSqglVFME/IUiliFUMsao0QAjUFoqSuC6orVQZlgIJ4Dg4lIstwA2xFVppo/X66R9z1p4ddmbPnDmXmX1/H2k1c85czrM7+8x7O+d9FRGYWVpOaDoAM6ufE98sQU58swQ58c0S5MQ3S5AT3yxBTnyzBA2U+JKukrRX0j5JW8oKysyqpaIn8EgaA34BXAnsB54Gro+Il8oLz8yqcOIAr70Q2BcRrwBIehC4Guia+MuWL4tTP3DqAIcsTr9S36/J+6Uo9f/eVcTRqVdccabP2CzFeNMBzPfuG+8y/evpRf8hB0n81cAbbdv7gY/2esGpHziVz/7jZwc4ZHFjW8f6fs3s7Gyu542PF/v0jx49WmocnXrFNXPDTKH3tA6rmg5gvkc/8Wiu51XeuSdpQtKUpKnpQ9NVH87MchikxD8ArG3bXpPtmyciJoFJgBXrVzRWv5zd3KXUnCz2flWX8lUbf+B4/J0xdf1b2Xu92WX/kNUEOg1S4j8NrJN0tqSTgM8BO8oJy8yqVLjEj4gjkm4GfgyMAfdHxIulRWZmlRmkqk9E/BD4YUmxmFlNBkr8JWGiY7tgm79sVfTk59U+AuL2fkHd2v6LqalvwKfsmiXIiW+WIFf1O7VX/Tuq/UWq0f0M3xWp3lc9rOhqf82KNhHm5DwvyyW+WYKc+GYJcuKbJcht/F46hvpm2hpQ7ae8dhqW03LLMK/foddQZ+ewqA01l/hmCXLimyXIVf2C2q9n71Xtr8JQDit2/A18vf9wc4lvliAnvlmCXNUvQWe1Nu80X0UvxMmrydGF9qq/q/3DxyW+WYKc+GYJcuKbJcht/Ar0vIqtwEQfZUyu0UvVk354Ys/h4xLfLEFOfLME1VvVH+f4nGKDTjhgC6pyCG/U1xKw41zimyXIiW+WICe+WYKaG86rYv7wUeg36DVhRdtQX972dNH2c9WnC+c1bzLPzpg8uUdlFi3xJd0v6aCkF9r2nS5pp6SXs9vTqg3TzMqUp6r/HeCqjn1bgF0RsQ7YlW2b2YhYNPEj4t+AX3fsvhrYlt3fBlxTclzFrGr7GUHj4+PHfkbd0aNHj/3Y8CnaubcyIuZa1G8BK0uKx8xqMHCvfkQEEN0elzQhaUrS1PQ704MezsxKULRX/21JqyLiTUmrgIPdnhgRk2T91SvOX9H1C8K6T1jROZ9dkepzP734Vc/p165nXN0uaHJv/8CKlvg7gE3Z/U3A9nLCMbM65BnO+x7wn8CHJO2XtBm4A7hS0svAH2fbZjYiFq3qR8T1XR66ouRYzKwmS2sijlE4c6+AYZ3M00aXz9U3S5AT3yxBS6uqv5T0OPtw9m+OV+HHvp6v2l+FqocV280bYnyg+/M8h38+LvHNEuTEN0uQE98sQW7jj7j29j4Ua/MP67z9Vh2X+GYJcuKbJchV/SWms+p/zO3zN+u8Aq+oIjF2Xsno4b2FucQ3S5AT3yxBruoPkyrnCvxqx/Y3KjwWxXryl8Jcg6PCJb5Zgpz4Zgly4pslyG38RM185fgw1/g3uret8w7hlXLVXQk64523RNdmn0E4xyW+WYKc+GYJclXf5lX7odnJPYrwMl39c4lvliAnvlmCnPhmCXIb396j2xV+Rdv+ZQzZNdqOr3rZ9QbWg8izhNZaSU9IeknSi5JuyfafLmmnpJez29OqD9fMypCnqn8E+FJErAcuAm6StB7YAuyKiHXArmzbzEZAnrXz3iSrjETEu5L2AKuBq4HLsqdtA54EvlxJlDaUqp5Lr7HqfdVV+6LHK7FJ0FfnnqSzgAuA3cDK7EsB4C1gZXlhmVmVcie+pFOAHwBfjIjftD8WEQFEl9dNSJqSNDX9zvRAwZpZOXIlvqRxWkn/3Yh4NNv9tqRV2eOrgIMLvTYiJiNiY0RsXHbGsjJiNrMBLdrGlyRgK7AnIr7Z9tAOYBNwR3a7vZIIe1miy2IPq3+4996uj904MTFvO+8QXp3t+JG/Ui9PX0DOkdM84/iXAH8K/EzSc9m+r9BK+IclbQZeA67Ld0gza1qeXv3/ANTl4SvKDcfM6uAz9yy3Gw/Mr87ft3ry+P377pv32M0337zgezR5Bp6X8jrO5+qbJciJb5YgV/WtsPaq/30dj/39Pfccu//nX/hCofd31bw6LvHNEuTEN0uQE98sQW7jWznU7VSP3tyOb4ZLfLMEOfHNEuSqvpXixqmOs/o+cnyAb/bGG+sOp391T77RMJf4Zgly4pslyIlvlqB62/gz5Js8o1d7aylNvrGU25Xtw3sdk3RY81zimyXIiW+WoOEczltK1flE3LdxsutjZSyhVbaZyflLg/PVZuJoikt8swQ58c0SNJxVfbOqJT7Q4BLfLEFOfLMEOfHNEuQ2vpWi8+q89uWq6DGX/gknuOwpxdwQ+EzPZx2z6F9d0jJJT0l6XtKLkm7P9p8tabekfZIeknRS4aDNrFZ5vm5/C1weEecDG4CrJF0E3AncFRHnAoeAzdWFaWZlyrN2XgD/m22OZz8BXA78SbZ/G/A1oPtyqvZeec9QHNaLeUo4w7LXklpuBlQn119W0li2Uu5BYCfwS+BwRBzJnrIfWF1NiGZWtlyJHxGzEbEBWANcCJyX9wCSJiRNSZqaPjRdMEwzK1NfdamIOAw8AVwMLJc011RYAxzo8prJiNgYERuXnbZsoGDNrByLtvElrQBmIuKwpPcBV9Lq2HsCuBZ4ENgEbK8y0KRVfbXikPYhFFlSu1e/wMwNOce6EpBnHH8VsE3SGK0awsMR8bikl4AHJX0deBbYWmGcZlaiPL36PwUuWGD/K7Ta+2Y2YnzmnpUzrNg5D8fYgs+qXJHmQYo8UGqWICe+WYJc1bf8+hhdKLIK7thYQ+2DBLnEN0uQE98sQU58swS5jW9Do1e/gNv/5XKJb5YgJ75ZglzVt5FQZHiwL+1DlUN60VKZXOKbJciJb5YgJ75ZgtzGt1L0Wgp7ZmbEJsDoZ+KTEe0PcIlvliAnvlmCXNW3yvVqBvRSShOh6uWwq5wPscJmhEt8swQ58c0S5Kq+FTb+QLEqfO7379JEGLlRgqIqbEa4xDdLkBPfLEFOfLMEuY1vhbXPYV/nktb9DA/OkEh/QJ9yf1rZUtnPSno82z5b0m5J+yQ9JOmk6sI0szL18zV9C7CnbftO4K6IOBc4BGwuMzAzq06uxJe0BvgU8O1sW8DlwCPZU7YB11QRoI2Go0ePdv2x4ZO3xP8WcCsw9ymeARyOiCPZ9n5gdcmxmVlFFk18SZ8GDkbEM0UOIGlC0pSkqelD00XewsxKlqdX/xLgM5I+CSwDfg+4G1gu6cSs1F8DHFjoxRExSbaW6or1K6KUqM1sIIsmfkTcBtwGIOky4K8i4vOSvg9cCzwIbAK2VxinDYGxrcXmti/azi8yRDhzg4fv8hhk8PXLwF9K2kerzb+1nJDMrGp9ncATEU8CT2b3XwEuLD8kM6uaz9yzoZW3iVDnWYNLhf9iZgly4pslqN6q/jjd5xGrcu4yK0U/y1jVubqtzw7sn0t8swQ58c0S5MQ3S9DwDOe1t/3d3h953foD6mz7W3cu8c0S5MQ3S9DwVPVtaExsnFxw/+TE4OtR9TMk2I2bC4NziW+WICe+WYKc+GYJchvf3mNyqktbfuGmf+3K6CdInUt8swQ58c0S5Kp+FbpdgVhUzWcyVjmcV4khDWuYucQ3S5AT3yxBruqPgn6aDr7AyXJwiW+WICe+WYKc+GYJcht/qSl7KHEYefhuYLkSX9KrwLvALHAkIjZKOh14CDgLeBW4LiIOVROmmZWpn6r+xyJiQ0RszLa3ALsiYh2wK9s2sxEwSBv/amBbdn8bcM3g4ZhZHfImfgA/kfSMpLkW1sqImBs1fgtYWXp0ZlaJvJ17l0bEAUm/D+yU9PP2ByMiJMVCL8y+KCYATll9ykDBmlk5cpX4EXEguz0IPEZreey3Ja0CyG4PdnntZERsjIiNy85YVk7UZjaQRUt8SScDJ0TEu9n9jwN/B+wANgF3ZLfbB4rEp5oOjaG9Cs9Kk6eqvxJ4TNLc8/8pIn4k6WngYUmbgdeA66oL08zKtGjiR8QrwPkL7H8HuKKKoMysWj5l1yxBTnyzBDnxzRLkxDdLkK/Os6Wt6qsVR3QY2iW+WYKc+GYJclXflpa6JyLJe7whaxK4xDdLkBPfLEHNVfWHrOozkBTmubPBFPkfqTBHXOKbJciJb5YgJ75ZghSx4IxZ1Rysy/RcZlaeiNBiz3GJb5YgJ75Zgnzmnr1Xe4Ns0UqjjSKX+GYJcuKbJciJb5YgJ75Zgpz4Zgly4pslaGiG815//fVj99euXTvvsbGxsWP3Z2dnj93PVvcxsz7lKvElLZf0iKSfS9oj6WJJp0vaKenl7Pa0qoM1s3LkrerfDfwoIs6jtZzWHmALsCsi1gG7sm0zGwGLXqQj6f3Ac8AHo+3JkvYCl0XEm9ky2U9GxIcWea+uB9u3b9+x++ecc07n647db4/XVf2K+My9kVbWRTpnA/8DPCDpWUnfzpbLXhkRc3OEvEVrVV0zGwF5Ev9E4MPAvRFxAfB/dFTrs5rAgqW5pAlJU5KmBg3WzMqRJ/H3A/sjYne2/QitL4K3syo+2e3BhV4cEZMRsTEiNpYRsJkNLtdEHJL+HfiziNgr6WvAydlD70TEHZK2AKdHxK2LvE9tE3F0/l7d+wOKhfSRHo8944axNShPGz/vOP5fAN+VdBLwCnADrdrCw5I2A68B1xUN1MzqtWSn3nKJb6ny1FtmtiAnvlmCnPhmCXLimyVoyXbumaXKnXtmtiAnvlmC6p6I41e0TvY5M7vfpGGIARxHJ8cxX79x/EGeJ9Xaxj92UGmq6XP3hyEGx+E4morDVX2zBDnxzRLUVOJPNnTcdsMQAziOTo5jvkriaKSNb2bNclXfLEG1Jr6kqyTtlbQvm7yjruPeL+mgpBfa9tU+PbiktZKekPSSpBcl3dJELJKWSXpK0vNZHLdn+8+WtDv7fB7K5l+onKSxbD7Hx5uKQ9Krkn4m6bm5aeIa+h+pZSr72hJf0hhwD/AJYD1wvaT1NR3+O8BVHfuamB78CPCliFgPXATclP0N6o7lt8DlEXE+sAG4StJFwJ3AXRFxLnAI2FxxHHNuoTVl+5ym4vhYRGxoGz5r4n+knqnsI6KWH+Bi4Mdt27cBt9V4/LOAF9q29wKrsvurgL11xdIWw3bgyiZjAX4X+C/go7ROFDlxoc+rwuOvyf6ZLwcepzWhdxNxvAqc2bGv1s8FeD/w32R9b1XGUWdVfzXwRtv2/mxfUxqdHlzSWcAFwO4mYsmq18/RmiR1J/BL4HBEHMmeUtfn8y3gVuBotn1GQ3EE8BNJz0iayPbV/bnUNpW9O/foPT14FSSdAvwA+GJE/KaJWCJiNiI20CpxLwTOq/qYnSR9GjgYEc/UfewFXBoRH6bVFL1J0h+1P1jT5zLQVPb9qDPxDwDtq2GuyfY1Jdf04GWTNE4r6b8bEY82GQtARBwGnqBVpV4uae76jTo+n0uAz0h6FXiQVnX/7gbiICIOZLcHgcdofRnW/bkMNJV9P+pM/KeBdVmP7UnA54AdNR6/0w5gU3Z/E632dqXUmvFzK7AnIr7ZVCySVkhant1/H61+hj20vgCurSuOiLgtItZExFm0/h/+NSI+X3cckk6WdOrcfeDjwAvU/LlExFvAG5LmlqK7Anipkjiq7jTp6KT4JPALWu3Jv67xuN8D3gRmaH2rbqbVltwFvAz8C611AaqO41Ja1bSf0lqP8Lnsb1JrLMAfAs9mcbwA/G22/4PAU8A+4PvA79T4GV0GPN5EHNnxns9+Xpz732zof2QDMJV9Nv8MnFZFHD5zzyxB7twzS5AT3yxBTnyzBDnxzRLkxDdLkBPfLEFOfLMEOfHNEvT/7+74qXnJxmYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "# Two problems:\n",
    "# 1. Not learning very much over 10 epochs\n",
    "# 2. Generate is not working at all\n",
    "vrnn = VRNN().to(device)\n",
    "vrnn.load_state_dict(torch.load('vrnn.pt', map_location='cpu'))\n",
    "\n",
    "img = np.load('/floyd/input/car_racing_data/trial_1995_0.npz')['obs'][120]\n",
    "img = Image.fromarray(img).resize((64,64))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "hidden = torch.randn(1,256).to(device)\n",
    "#vrnn.generate_images(1)\n",
    "im = vrnn(ToTensor()(img).unsqueeze_(0).to(device),hidden)[0].detach()\n",
    "print(im.permute(0,2,3,1).shape)\n",
    "plt.imshow(im.permute((0,2,3,1))[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0355bb170f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mim_to_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_to_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    }
   ],
   "source": [
    "img = im.cpu().permute((0,2,3,1))\n",
    "for _ in range(50):\n",
    "    im_to_show = img.detach().numpy()[0]\n",
    "    plt.imshow(im_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1 # 100\n",
    "MAX_SEQ_LEN = 199 # 999\n",
    "\n",
    "LATENT_VEC = 50\n",
    "HIDDEN_UNITS = 256\n",
    "HIDDEN_DIM = 256\n",
    "TEMPERATURE = 1.15\n",
    "GAUSSIANS = 5\n",
    "NUM_LAYERS = 1\n",
    "PARAMS_CONTROLLER = HIDDEN_UNITS * NUM_LAYERS * 2 + LATENT_VEC\n",
    "MDN_CONST = 1.0 / math.sqrt(2.0 * math.pi)\n",
    "EPSILON = 1e-6\n",
    "\n",
    "MAX_PLAYS = MAX_SEQ_LEN + 1\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, sequence_len, batch_size, hidden_units, z_dim, num_layers, n_gaussians, hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self.num_layers = num_layers\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.sequence_len = sequence_len\n",
    "        self.hidden = self.init_hidden(self.sequence_len)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.z_dim + 3, self.hidden_dim)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, hidden_units, num_layers)\n",
    "        self.z_pi = nn.Linear(hidden_units, n_gaussians * self.z_dim)\n",
    "        self.z_sigma = nn.Linear(hidden_units, n_gaussians * self.z_dim)\n",
    "        self.z_mu = nn.Linear(hidden_units, n_gaussians * self.z_dim) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        sequence = x.size()[1]\n",
    "\n",
    "        # Hidden state\n",
    "        x = F.relu(self.fc1(x))\n",
    "        z, self.hidden = self.lstm(x, self.hidden)\n",
    "\n",
    "        pi = self.z_pi(z).view(-1, sequence, self.n_gaussians, self.z_dim)\n",
    "        pi = F.softmax(pi, dim=2)\n",
    "        pi = pi / TEMPERATURE\n",
    "\n",
    "        sigma = torch.exp(self.z_sigma(z)).view(-1, sequence,\n",
    "                        self.n_gaussians, self.z_dim)\n",
    "        sigma = sigma * (TEMPERATURE ** 0.5)\n",
    "        mu = self.z_mu(z).view(-1, sequence, self.n_gaussians, self.z_dim)\n",
    "    \n",
    "        return pi, sigma, mu\n",
    "\n",
    "\n",
    "    def init_hidden(self, sequence):\n",
    "        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_units, device=device)\n",
    "        cell = torch.zeros(self.num_layers, self.batch_size, self.hidden_units, device=device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Instanciate a dataset extending PyTorch \"\"\"\n",
    "        self.frames = []\n",
    "        self.actions = []\n",
    "        self.done = False\n",
    "        \n",
    "#         with open('/Users/zachrash/Desktop/driving_data/driving_log.csv') as f:\n",
    "#             data = csv.reader(f, delimiter=',')\n",
    "#             i = 0\n",
    "#             frame = []\n",
    "#             action = []\n",
    "#             for j, (im, _, _, steering_angle, _, _, _) in enumerate(data):\n",
    "#                 frame.append(np.array(Image.open(im).convert('RGB').resize((128,128))))\n",
    "#                 action.append(float(steering_angle))\n",
    "#                 i += 1\n",
    "#                 if i == MAX_PLAYS:\n",
    "#                     self.frames.append(frame)\n",
    "#                     self.actions.append(action)\n",
    "#                     frame = []\n",
    "#                     action = []\n",
    "#                     i = 0\n",
    "\n",
    "        data_arr = []\n",
    "        for i in os.listdir('/floyd/input/car_racing_data/'):\n",
    "            data_arr.append(np.load(os.path.join('/floyd/input/car_racing_data/', i)))\n",
    "        c = 0\n",
    "        action = []\n",
    "        frame = []\n",
    "        for data in data_arr:\n",
    "            for ob in data['obs']:\n",
    "                frame.append(np.array(Image.fromarray(ob).resize((64,64))))\n",
    "            for act in data['action']:\n",
    "                action.append(np.array(act))\n",
    "        \n",
    "        self.frames = np.array_split(frame, len(frame) / MAX_PLAYS)\n",
    "        self.actions = np.array_split(action, len(action) / MAX_PLAYS)\n",
    "        temp = list(zip(self.frames, self.actions))\n",
    "        np.random.shuffle(temp)\n",
    "        frames, actions = zip(*temp)\n",
    "        self.frames = np.array(frames)\n",
    "        self.actions = np.array(actions)\n",
    "                \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.frames.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return zs, actions\"\"\"\n",
    "        if self.frames[idx].shape[0] == 201:\n",
    "            self.frames[idx] = self.frames[idx][:-1,:,:,:]\n",
    "        if self.actions[idx].shape[0] == 201:\n",
    "            self.actions[idx] = self.actions[idx][:-1,:]\n",
    "        return np.rollaxis(self.frames[idx], 3, 1), \\\n",
    "               self.actions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-10-3bdd56eef1bf>\", line 55, in __getitem__\n    return np.rollaxis(self.frames[idx], 3, 1),                self.actions[idx]\n  File \"/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\", line 1451, in rollaxis\n    axis = normalize_axis_index(axis, n)\nnumpy.core._internal.AxisError: axis 3 is out of bounds for array of dimension 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-bc9fbf70bda1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataloadertest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloadertest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#print c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-10-3bdd56eef1bf>\", line 55, in __getitem__\n    return np.rollaxis(self.frames[idx], 3, 1),                self.actions[idx]\n  File \"/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\", line 1451, in rollaxis\n    axis = normalize_axis_index(axis, n)\nnumpy.core._internal.AxisError: axis 3 is out of bounds for array of dimension 1\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "d = LSTMDataset()\n",
    "dataloadertest = DataLoader(d, batch_size=1, num_workers=4, collate_fn=collate_fn)\n",
    "for im, ac in dataloadertest:\n",
    "    for i in im:\n",
    "        #print c\n",
    "        i = i.permute(1,2,0)\n",
    "        plt.imshow(i)\n",
    "        plt.show()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss_function(out_pi, out_sigma, out_mu, y):\n",
    "    \"\"\"\n",
    "    Mixed Density Network loss function, see : \n",
    "    https://mikedusenberry.com/mixture-density-networks\n",
    "    \"\"\"\n",
    "    result = Normal(loc=out_mu, scale=out_sigma)\n",
    "    y = y.view(MAX_SEQ_LEN+1, BATCH_SIZE, LATENT_VEC+3)\n",
    "    result = torch.exp(result.log_prob(y))\n",
    "    result = torch.sum(result * out_pi, dim=2)\n",
    "    result = -torch.log(EPSILON + result)\n",
    "    return torch.mean(result)\n",
    "\n",
    "\n",
    "def sample_z(pi, sigma, mu):\n",
    "    return torch.sum(pi*(mu+sigma), dim=2)\n",
    "\n",
    "\n",
    "def collate_fn(example):\n",
    "    \"\"\" Custom way of flattening examples in a batch \"\"\"\n",
    "    frames = []\n",
    "    actions = []\n",
    "    for ex in example:\n",
    "        frames.extend(ex[0])\n",
    "        actions.extend(ex[1])\n",
    "    frames = torch.tensor(frames, dtype=torch.float) / 255.0\n",
    "    actions = torch.tensor(actions, dtype=torch.float)\n",
    "    return frames, actions\n",
    "\n",
    "\n",
    "def train_lstm():\n",
    "    # Init VAE\n",
    "    vae = VAE((320, 160, 3), 50).to(device)\n",
    "    vae.load_state_dict(torch.load('model.pt', map_location='cpu'))\n",
    "    \n",
    "    # Init LSTM\n",
    "    lstm = LSTM(MAX_SEQ_LEN, BATCH_SIZE, HIDDEN_UNITS, LATENT_VEC, NUM_LAYERS, GAUSSIANS, HIDDEN_DIM).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    dataset = LSTMDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=4, collate_fn=collate_fn)\n",
    "    epochs = 100\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        print(\"Epoch: {}/{}\".format(e+1, epochs))\n",
    "        for batch_idx, (frames, actions) in enumerate(dataloader):\n",
    "            frames = frames.squeeze_(0).to(device)\n",
    "            actions = actions.squeeze_(0).to(device)\n",
    "            encoded = vae(frames, encode=True)\n",
    "            example = {\n",
    "                'encoded': encoded,\n",
    "                'actions' : actions\n",
    "            }\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            lstm.hidden = lstm.init_hidden(MAX_SEQ_LEN+3) # ??\n",
    "#             x = torch.cat((example['encoded'],\n",
    "#                            example['actions'].view(-1, 3)), dim=1)\n",
    "#             x = x.view(MAX_SEQ_LEN+1, BATCH_SIZE, LATENT_VEC + 3)\n",
    "#             print(x.shape)\n",
    "\n",
    "#             ## Shift target encoded vector\n",
    "#             last_ex = example['encoded'][-1].view(-1, example['encoded'].size()[1])\n",
    "#             print(last_ex.shape)\n",
    "#             target = torch.cat((example['encoded'][1:example['encoded'].size()[0]],\\\n",
    "#                                   last_ex,), dim=1)\n",
    "#             print (target.shape)\n",
    "            \n",
    "            x = torch.cat((example['encoded'],\n",
    "                    example['actions']), dim=1)\n",
    "            #print(x.shape)\n",
    "            x = x.view(MAX_SEQ_LEN+1, 1, LATENT_VEC + 3)\n",
    "            #print(x_raw.shape)\n",
    "            # x = x_raw[:-1,:,:]\n",
    "            print(x.shape)\n",
    "            # print(example['encoded'][1:,:].unsqueeze_(0).shape)\n",
    "            target = example['encoded'][1:,:].unsqueeze_(0).view(MAX_SEQ_LEN, BATCH_SIZE, LATENT_VEC)\n",
    "            # print (target.shape)\n",
    "            \n",
    "            last_ex = example['encoded'][-1].view(-1, example['encoded'].size()[1])\n",
    "            target = torch.cat((example['encoded'][1:example['encoded'].size()[0]],last_ex,))\n",
    "            pi, sigma, mu = lstm(x)\n",
    "            loss = mdn_loss_function(pi, sigma, mu, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx %20 == 0:\n",
    "                print('Loss: {}'.format(float(loss.data)))\n",
    "            \n",
    "    torch.save(lstm.state_dict(), 'lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "torch.Size([200, 1, 53])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: size '[200 x 1 x 53]' is invalid for input with 10000 elements at /pytorch/aten/src/TH/THStorage.cpp:84",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-18c7a05580ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-2420165fab34>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdn_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-2420165fab34>\u001b[0m in \u001b[0;36mmdn_loss_function\u001b[0;34m(out_pi, out_sigma, out_mu, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQ_LEN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_VEC\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: size '[200 x 1 x 53]' is invalid for input with 10000 elements at /pytorch/aten/src/TH/THStorage.cpp:84"
     ]
    }
   ],
   "source": [
    "train_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(1, BATCH_SIZE, HIDDEN_UNITS, LATENT_VEC, NUM_LAYERS, GAUSSIANS, HIDDEN_DIM).to(device)\n",
    "lstm.load_state_dict(torch.load('lstm.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zachrash/Desktop/driving_data/driving_log.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-71202efc2680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/zachrash/Desktop/driving_data/driving_log.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mangles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zachrash/Desktop/driving_data/driving_log.csv'"
     ]
    }
   ],
   "source": [
    "# Test VAE + LSTM\n",
    "data_dir = '/Users/zachrash/Desktop/driving_data/driving_log.csv'\n",
    "r = random.randint(0, 800)\n",
    "with open(data_dir, 'r') as f:\n",
    "    data = csv.reader(f, delimiter=',')\n",
    "    angles = []\n",
    "    for i, (images,_,_,a,_,_,_) in enumerate(data):\n",
    "        angles.append(float(a))\n",
    "        if i == r:\n",
    "            f_image = images\n",
    "            f_a = a\n",
    "        if i == r+30:\n",
    "            s_image = images\n",
    "            s_a = a\n",
    "\n",
    "im = vae(ToTensor()(Image.open(f_image).convert('RGB').resize((64,128))).unsqueeze_(0))[0]\n",
    "z = vae(ToTensor()(Image.open(f_image).convert('RGB').resize((128,128))).unsqueeze_(0), encode=True)\n",
    "next_z = z\n",
    "# for i in range(30):\n",
    "#     next_z = next_z[0]\n",
    "#     inp = torch.cat((z.unsqueeze_(0), torch.tensor([[angles[i]]])), dim=1).unsqueeze_(0)\n",
    "#     pi, sigma, mu = lstm(inp)\n",
    "#     _, z_next = torch.max(pi[0,0,:,:], 0)\n",
    "\n",
    "z = z[0].float()\n",
    "inp = torch.cat((z.unsqueeze_(0), torch.tensor([[angles[i]]])), dim=1).unsqueeze_(0)\n",
    "pi, sigma, mu = lstm(inp)\n",
    "\n",
    "z = sample_z(pi, sigma, mu)[0,0,:,:]\n",
    "\n",
    "im = vae.decode(z.float())\n",
    "im = ToPILImage()(im[0,:,:,:])\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "# print pi[0].shape\n",
    "# print np.max(pi[0,0,:,:].detach().numpy())\n",
    "# for p in pi[0,0,:,:]:\n",
    "#     zs.append(p)\n",
    "\n",
    "# for z in zs:\n",
    "#     im = vae.decode(z.float())\n",
    "#     im = ToPILImage()(im[0,:,:,:])\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()\n",
    "# _, z_next = torch.max(pi[0,0,:,:], 0)\n",
    "\n",
    "# next_im = vae.decode(z_next.float())\n",
    "# next_im = ToPILImage()(next_im[0,:,:,:])    \n",
    "# im = ToPILImage()(im[0,:,:,:])\n",
    "# plt.imshow(Image.open(f_image))\n",
    "# plt.show()\n",
    "# plt.imshow(im)\n",
    "# plt.show()\n",
    "# plt.imshow(Image.open(s_image))\n",
    "# plt.show()\n",
    "# plt.imshow(next_im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a4062c0bfdad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mz_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Test Generative M\n",
    "z_next = Normal(0, 1).sample((1,50))\n",
    "\n",
    "for i in range(1000):\n",
    "    x = torch.cat((z_next,\n",
    "                  torch.Tensor([0.0]).unsqueeze_(0),\n",
    "                  torch.Tensor([1.0]).unsqueeze_(0),\n",
    "                  torch.Tensor([0.0]).unsqueeze_(0)), dim=1)\n",
    "    z_next = lstm(x.unsqueeze_(0).to(device))\n",
    "    z_next = sample_z(*z_next)\n",
    "    next_im = vae.decode(z_next.to(device))\n",
    "    z_next = z_next.squeeze_(0)\n",
    "    if i %100 == 0:\n",
    "        plt.imshow(ToPILImage()(next_im[0,:,:,:]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
